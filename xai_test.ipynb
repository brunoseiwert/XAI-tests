{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is here to suppress annoying progress bars that DiCE generates wih tqdm\n",
    "import tqdm\n",
    "\n",
    "def tqdm_replacement(iterable_object,*args,**kwargs):\n",
    "    return iterable_object\n",
    "\n",
    "tqdm.tqdm = tqdm_replacement\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dice_ml\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_X, credit_y = fetch_openml(data_id=31, parser=\"auto\", as_frame=True, return_X_y=True)\n",
    "\n",
    "feature_names = ['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents']\n",
    "\n",
    "# only keep the features of feature_names in dataset\n",
    "credit_X = credit_X.drop([feature for feature in credit_X.columns if feature not in feature_names], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit_X, credit_y, test_size=0.2, stratify=credit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duration                     48\n",
       "credit_amount             12204\n",
       "installment_commitment        2\n",
       "residence_since               2\n",
       "age                          48\n",
       "existing_credits              1\n",
       "num_dependents                1\n",
       "Name: 615, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just an instance with bad credit rating\n",
    "instance = X_test.iloc[2]\n",
    "print(model.predict([instance]))\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .lime {\n",
       "        background-color: white;\n",
       "        }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .lime {\n",
    "        background-color: white;\n",
    "        }\n",
    "</style>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer = LimeTabularExplainer(X_train.to_numpy(),\n",
    "                                      feature_names=feature_names,\n",
    "                                      class_names=['bad', 'good'])\n",
    "\n",
    "predict_fn = lambda x: model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=pd.concat([credit_X, credit_y], axis=1), continuous_features=feature_names, outcome_name='class')\n",
    "m = dice_ml.Model(model=model, backend='sklearn')\n",
    "\n",
    "dice_explainer = dice_ml.Dice(d, m, method='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfactuals(instance: pd.Series, amount: int = 3):\n",
    "    '''\n",
    "    Returns a list of counterfactuals as dictionaries where the entries show differences to the input instance.\n",
    "    Of course, the output class is also different.\n",
    "    '''\n",
    "    exp = dice_explainer.generate_counterfactuals(instance.to_frame().T,\n",
    "                                                total_CFs=amount, \n",
    "                                                desired_class='opposite',\n",
    "                                                features_to_vary=['duration', 'credit_amount', 'installment_commitment', 'existing_credits'])\n",
    "    #exp.visualize_as_dataframe(show_only_changes=True)\n",
    "    cfs_list = [row.to_dict() for _, row in exp.cf_examples_list[0].final_cfs_df.iterrows()]\n",
    "    for cf in cfs_list:\n",
    "        for feature, value in instance.to_dict().items():\n",
    "            if cf[feature] == value:\n",
    "                del cf[feature]\n",
    "        del cf['class']\n",
    "    return cfs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lime_explanation(instance: pd.Series, num_features: int = 3):\n",
    "    '''\n",
    "    Returns a list of feature weights of the lime explanation for the input instance.\n",
    "    '''\n",
    "    expl = lime_explainer.explain_instance(instance, predict_fn, num_features=num_features)\n",
    "    return expl.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# load and set our api key\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "message_history = []\n",
    "def append_message(message, role=\"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": f\"{message}\"})\n",
    "    \n",
    "def append_function_call(name, arguments=\"{}\"):\n",
    "    message_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": None,\n",
    "        \"function_call\": {\n",
    "            \"name\": name,\n",
    "            \"arguments\": arguments\n",
    "        }\n",
    "    })\n",
    "    \n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"explain_instance\",\n",
    "        \"description\": '''Explains the current instance or decision to the user.\n",
    "            Returns a list of the top features that where most important in the decision of the model.\n",
    "            This function should be called when the user asks questions such as \"Why was my loan rejected?\",\n",
    "            \"Why did the model decide this?\", \"What were the most important features for this decision?\" or \"Can you explain this to me?\".\n",
    "            It has no paramters.''',\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"change_feature\",\n",
    "        \"description\": '''Changes a feature of the current instance that is explained.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"feature_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": feature_names,\n",
    "                    \"description\": \"The name of the feature that will be changed.\"\n",
    "                },\n",
    "                \"new_value\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The new value of the feature.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"feature_name\", \"new_value\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"generate_counterfactuals\",\n",
    "        \"description\": '''Generates potential scenarios where the models decision is different from the current decision.\n",
    "            So for example if the customers asks what they could do to get a good credit rating, this method should be called.\n",
    "            Should be called when the user asks questions such as \"How can I get the loan?\", \"What can I do in order to get the loan?\"\n",
    "            or \"What would need to happen for me to get a good credit rating?\".''',\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
    "    }\n",
    "]\n",
    "\n",
    "def explain_with_lime():\n",
    "    credit_rating = model.predict([instance])[0]\n",
    "    explanation = generate_lime_explanation(instance, 5)\n",
    "    # inject 'positive' for positve weight and vice versa, so GPT understands better\n",
    "    for i in range(len(explanation)):\n",
    "        if explanation[i][1] >= 0:\n",
    "            explanation[i] = (explanation[i][0], 'positive with ' + str(explanation[i][1]))\n",
    "        else:\n",
    "            explanation[i] = (explanation[i][0], 'negative with ' + str(explanation[i][1]))\n",
    "    # if credit_rating == 'bad':\n",
    "    #     explanation = [entry for entry in explanation if entry[1] < 0]\n",
    "    # else:\n",
    "    #     explanation = [entry for entry in explanation if entry[1] >= 0]\n",
    "        \n",
    "    message = f'''Here is a list with features and their weight in the decision for the rating: {explanation}.\n",
    "    Positive weights indicate a good rating, meaning loan acceptance. Negative weights indicate a bad rating, meaning loan rejection.\n",
    "    The model gave the user a {credit_rating} rating. Explain the models decision for lay users and keep it short.\n",
    "    Focus on the most important feature'''\n",
    "    append_message(message)\n",
    "    \n",
    "def explain_with_counterfactuals():\n",
    "    credit_rating = model.predict([instance])[0]\n",
    "    cfs = generate_counterfactuals(instance, amount=1)\n",
    "    cfs_string = ' or '.join([str(cf) for cf in cfs])\n",
    "    message = f'''The credit rating is '{credit_rating}'. The users features are {str(instance.to_dict())}.\n",
    "    In order to not get that credit rating, the user should make the following changes: {cfs_string}.\n",
    "    If the user changed the features like that, the credit rating would definetly change.\n",
    "    Explain this to the user in simple terms and keep it short.'''\n",
    "    append_message(message)\n",
    "    \n",
    "def change_feature(feature_name, new_value):\n",
    "    if feature_name not in feature_names:\n",
    "        print(\"error\")\n",
    "        #feature does not exist\n",
    "        append_message(\"Tell the user that the feature does not exist\", \"system\")\n",
    "        return\n",
    "    new_value = float(new_value)\n",
    "    instance[feature_name] = new_value\n",
    "    append_message(f\"The users features are now {instance.to_dict()}. Inform the user about the feature change in a very short sentence\")\n",
    "\n",
    "functions_map = {\n",
    "    \"explain_instance\": explain_with_lime,\n",
    "    \"change_feature\": change_feature,\n",
    "    \"generate_counterfactuals\": explain_with_counterfactuals\n",
    "}\n",
    "\n",
    "def handle_function_call(fc):\n",
    "    name = fc[\"name\"]\n",
    "    #print(f\"Function called: '{name}'\")\n",
    "    append_function_call(name, fc[\"arguments\"])\n",
    "    arguments = json.loads(fc[\"arguments\"])\n",
    "    function = functions_map[name]\n",
    "    if arguments == {}:\n",
    "        function()\n",
    "    else:\n",
    "        function(**arguments)\n",
    "    # in case of a function call, the model is queried behind the scenes but it should not call another function\n",
    "    next_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=message_history,\n",
    "        functions=functions,\n",
    "        function_call=\"none\"\n",
    "    )\n",
    "    handle_completion(next_completion)\n",
    "\n",
    "def handle_completion(completion):\n",
    "    message = completion.choices[0].message.to_dict()\n",
    "    \n",
    "    # function call\n",
    "    if message[\"content\"] == None:\n",
    "        handle_function_call(message[\"function_call\"])\n",
    "    # normal answer\n",
    "    else:\n",
    "        append_message(message[\"content\"], role=\"assistant\")\n",
    "        print(message[\"content\"])\n",
    "        \n",
    "def chat(inp, role=\"user\"):\n",
    "    append_message(inp, role)\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=message_history,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\"\n",
    "    )\n",
    "    handle_completion(completion)\n",
    "    \n",
    "# describe the bot functionality\n",
    "bot_description = f'''You are an explanation system for a credit scoring AI model. You explain the decisions and classifications of the model.\n",
    "The model gives a customer a credit rating. The rating can either be 'good' or 'bad'.\n",
    "'good' means the customers loan request is accepted, 'bad' means the loan is rejected.\n",
    "The model uses a Random Forest Classifier to decide whether the person has a good or bad credit rating.\n",
    "The model was trained on 800 instances.\n",
    "The features the model uses in the classifying the customers credit/loan risk:\n",
    "duration: Duration of the loan/credit in months.\n",
    "credit_amount: The amount of the credit.\n",
    "installment_commitment: Installment rate in percentage of disposable income.\n",
    "residence_since: How long the customer has lived at his current residence in years.\n",
    "age: Age of the customer in years.\n",
    "existing_credits: Number of existing credits at this bank.\n",
    "num_dependents: Number of people the customer is liable to provide maintenance for.\n",
    "\n",
    "When the users asks questions about the model, you can either call an explanation function or elaborate on previous explanations.\n",
    "Only answer questions about the model, its decisions and the customers features it is using!\n",
    "Do not answer questions related to anything else!\n",
    "When asked about a different topic, remind the user to ask questions about the model.\n",
    "The users features are {instance.to_dict()}'''\n",
    "\n",
    "# Inject \"past\" dialogue into the api. The intention is to \"teach\" the model how it should answer the users questions.\n",
    "message_history = []\n",
    "append_message(bot_description)\n",
    "append_message(\"OK\", \"assistant\")\n",
    "append_message(\"How big is the sun?\")\n",
    "append_message(\"Please ask questions about the model.\", \"assistant\")\n",
    "append_message(\"How do I use a bottle opener?\")\n",
    "append_message(\"Please ask questions about the model.\", \"assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Why was my loan rejected?\n",
      "\n",
      "The model rejected your loan request primarily because of the duration of the loan. The longer the duration, the more likely it is for the loan to be rejected.\n",
      "\n",
      "User:  What impacted the decision negatively?\n",
      "\n",
      "The factors that had a negative impact on the decision were the duration of the loan and the credit amount. A longer duration and a higher credit amount resulted in a higher chance of loan rejection.\n",
      "\n",
      "User:  Was my age important?\n",
      "\n",
      "Yes, your age also played a role in the decision. The model considered your age and it had a positive impact, meaning that being older increased the likelihood of getting a good credit rating. However, it was not the most influential factor in this case.\n",
      "\n",
      "User:  What can I do to get the loan?\n",
      "\n",
      "To improve your credit rating and increase the chances of getting the loan, you can consider reducing the duration of the loan to 4 months and lowering the credit amount to 7191. These changes would have a positive impact on your credit rating.\n",
      "\n",
      "User:  How many people was this model trained on?\n",
      "\n",
      "The model was trained on 800 instances.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    user_input = input(\"> \")\n",
    "    print(\"User: \", user_input)\n",
    "    print()\n",
    "    chat(user_input)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"You are an explanation system for a credit scoring AI model. You explain the decisions and classifications of the model.\\nThe model gives a customer a credit rating. The rating can either be 'good' or 'bad'.\\n'good' means the customers loan request is accepted, 'bad' means the loan is rejected.\\nThe model uses a Random Forest Classifier to decide whether the person has a good or bad credit rating.\\nThe model was trained on 800 instances.\\nThe features the model uses in the classifying the customers credit/loan risk:\\nduration: Duration of the loan/credit in months.\\ncredit_amount: The amount of the credit.\\ninstallment_commitment: Installment rate in percentage of disposable income.\\nresidence_since: How long the customer has lived at his current residence in years.\\nage: Age of the customer in years.\\nexisting_credits: Number of existing credits at this bank.\\nnum_dependents: Number of people the customer is liable to provide maintenance for.\\n\\nWhen the users asks questions about the model, you can either call an explanation function or elaborate on previous explanations.\\nOnly answer questions about the model, its decisions and the customers features it is using!\\nDo not answer questions related to anything else!\\nWhen asked about a different topic, remind the user to ask questions about the model.\\nThe users features are {'duration': 48, 'credit_amount': 12204, 'installment_commitment': 2, 'residence_since': 2, 'age': 48, 'existing_credits': 1, 'num_dependents': 1}\"},\n",
       " {'role': 'assistant', 'content': 'OK'},\n",
       " {'role': 'user', 'content': 'How big is the sun?'},\n",
       " {'role': 'assistant', 'content': 'Please ask questions about the model.'},\n",
       " {'role': 'user', 'content': 'How do I use a bottle opener?'},\n",
       " {'role': 'assistant', 'content': 'Please ask questions about the model.'},\n",
       " {'role': 'user', 'content': 'Why was my loan rejected?'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'explain_instance', 'arguments': '{}'}},\n",
       " {'role': 'user',\n",
       "  'content': \"Here is a list with features and their weight in the decision for the rating: [('duration > 24.00', 'negative with -0.1382825696701693'), ('age > 41.00', 'positive with 0.08644189929039668'), ('credit_amount > 3870.50', 'negative with -0.06668410290761759'), ('installment_commitment <= 2.00', 'positive with 0.05805078302421479'), ('existing_credits <= 1.00', 'negative with -0.04680102350881535')].\\n    Positive weights indicate a good rating, meaning loan acceptance. Negative weights indicate a bad rating, meaning loan rejection.\\n    The model gave the user a bad rating. Explain the models decision for lay users and keep it short.\\n    Focus on the most important feature\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The model rejected your loan request primarily because of the duration of the loan. The longer the duration, the more likely it is for the loan to be rejected.'},\n",
       " {'role': 'user', 'content': 'What impacted the decision negatively?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The factors that had a negative impact on the decision were the duration of the loan and the credit amount. A longer duration and a higher credit amount resulted in a higher chance of loan rejection.'},\n",
       " {'role': 'user', 'content': 'Was my age important?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Yes, your age also played a role in the decision. The model considered your age and it had a positive impact, meaning that being older increased the likelihood of getting a good credit rating. However, it was not the most influential factor in this case.'},\n",
       " {'role': 'user', 'content': 'What can I do to get the loan?'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'generate_counterfactuals', 'arguments': '{}'}},\n",
       " {'role': 'user',\n",
       "  'content': \"The credit rating is 'bad'. The users features are {'duration': 48, 'credit_amount': 12204, 'installment_commitment': 2, 'residence_since': 2, 'age': 48, 'existing_credits': 1, 'num_dependents': 1}.\\n    In order to not get that credit rating, the user should make the following changes: {'duration': 4, 'credit_amount': 7191}.\\n    If the user changed the features like that, the credit rating would definetly change.\\n    Explain this to the user in simple terms and keep it short.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'To improve your credit rating and increase the chances of getting the loan, you can consider reducing the duration of the loan to 4 months and lowering the credit amount to 7191. These changes would have a positive impact on your credit rating.'},\n",
       " {'role': 'user', 'content': 'How many people was this model trained on?'},\n",
       " {'role': 'assistant', 'content': 'The model was trained on 800 instances.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
