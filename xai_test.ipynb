{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is here to suppress annoying progress bars that DiCE generates wih tqdm\n",
    "import tqdm\n",
    "\n",
    "def tqdm_replacement(iterable_object,*args,**kwargs):\n",
    "    return iterable_object\n",
    "\n",
    "tqdm.tqdm = tqdm_replacement\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dice_ml\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_X, credit_y = fetch_openml(data_id=31, parser=\"auto\", as_frame=True, return_X_y=True)\n",
    "\n",
    "feature_names = ['duration', 'credit_amount', 'installment_commitment', 'residence_since', 'age', 'existing_credits', 'num_dependents']\n",
    "\n",
    "# only keep the features of feature_names in dataset\n",
    "credit_X = credit_X.drop([feature for feature in credit_X.columns if feature not in feature_names], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit_X, credit_y, test_size=0.2, stratify=credit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duration                     48\n",
       "credit_amount             12204\n",
       "installment_commitment        2\n",
       "residence_since               2\n",
       "age                          48\n",
       "existing_credits              1\n",
       "num_dependents                1\n",
       "Name: 615, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just an instance with bad credit rating\n",
    "originalInstance = X_test.iloc[2]\n",
    "instance = originalInstance.copy()\n",
    "print(model.predict([instance]))\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .lime {\n",
       "        background-color: white;\n",
       "        }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .lime {\n",
    "        background-color: white;\n",
    "        }\n",
    "</style>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer = LimeTabularExplainer(X_train.to_numpy(),\n",
    "                                      feature_names=feature_names,\n",
    "                                      class_names=['bad', 'good'])\n",
    "\n",
    "predict_fn = lambda x: model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=pd.concat([credit_X, credit_y], axis=1), continuous_features=feature_names, outcome_name='class')\n",
    "m = dice_ml.Model(model=model, backend='sklearn')\n",
    "\n",
    "dice_explainer = dice_ml.Dice(d, m, method='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counterfactuals(instance: pd.Series, amount: int = 3):\n",
    "    '''\n",
    "    Returns a list of counterfactuals as dictionaries where the entries show differences to the input instance.\n",
    "    Of course, the output class is also different.\n",
    "    '''\n",
    "    exp = dice_explainer.generate_counterfactuals(instance.to_frame().T,\n",
    "                                                total_CFs=amount, \n",
    "                                                desired_class='opposite',\n",
    "                                                features_to_vary=['duration', 'credit_amount', 'installment_commitment', 'existing_credits'])\n",
    "    #exp.visualize_as_dataframe(show_only_changes=True)\n",
    "    cfs_list = [row.to_dict() for _, row in exp.cf_examples_list[0].final_cfs_df.iterrows()]\n",
    "    for cf in cfs_list:\n",
    "        for feature, value in instance.to_dict().items():\n",
    "            if cf[feature] == value:\n",
    "                del cf[feature]\n",
    "        del cf['class']\n",
    "    return cfs_list\n",
    "\n",
    "def generate_lime_explanation(instance: pd.Series, num_features: int = 3):\n",
    "    '''\n",
    "    Returns a list of feature weights of the lime explanation for the input instance.\n",
    "    '''\n",
    "    expl = lime_explainer.explain_instance(instance, predict_fn, num_features=num_features)\n",
    "    return expl.as_list()\n",
    "\n",
    "def get_credit_rating(instance: pd.Series):\n",
    "    return model.predict([instance])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# load and set our api key\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "message_history = []\n",
    "def append_message(message, role=\"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": f\"{message}\"})\n",
    "    \n",
    "def append_function_call(name, arguments=\"{}\"):\n",
    "    message_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": None,\n",
    "        \"function_call\": {\n",
    "            \"name\": name,\n",
    "            \"arguments\": arguments\n",
    "        }\n",
    "    })\n",
    "    \n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"explain_instance\",\n",
    "        \"description\": '''Explains the current instance or decision to the user.\n",
    "            Returns a list of the top features that where most important in the decision of the model.\n",
    "            This function should be called when the user asks questions such as \"Why was my loan rejected?\",\n",
    "            \"Why did the model decide this?\", \"What were the most important features for this decision?\" or \"Can you explain this to me?\".\n",
    "            It has no paramters.''',\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"change_feature\",\n",
    "        \"description\": '''Changes a feature of the current instance that is explained.''',\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"feature_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": feature_names,\n",
    "                    \"description\": \"The name of the feature that will be changed.\"\n",
    "                },\n",
    "                \"new_value\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The new value of the feature.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"feature_name\", \"new_value\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"generate_counterfactuals\",\n",
    "        \"description\": '''Generates potential scenarios where the models decision is different from the current decision.\n",
    "            So for example if the customers asks what they could do to get a good credit rating, this method should be called.\n",
    "            Should be called when the user asks questions such as \"How can I get the loan?\", \"What can I do in order to get the loan?\"\n",
    "            or \"What would need to happen for me to get a good credit rating?\".''',\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}}\n",
    "    }\n",
    "]\n",
    "\n",
    "def explain_with_lime():\n",
    "    credit_rating = get_credit_rating(instance)\n",
    "    explanation = generate_lime_explanation(instance, len(feature_names))\n",
    "    # inject 'positive' for positve weight and vice versa, so GPT understands better\n",
    "    for i in range(len(explanation)):\n",
    "        if explanation[i][1] >= 0:\n",
    "            explanation[i] = (explanation[i][0], 'positive with ' + str(explanation[i][1]))\n",
    "        else:\n",
    "            explanation[i] = (explanation[i][0], 'negative with ' + str(explanation[i][1]))\n",
    "    # if credit_rating == 'bad':\n",
    "    #     explanation = [entry for entry in explanation if entry[1] < 0]\n",
    "    # else:\n",
    "    #     explanation = [entry for entry in explanation if entry[1] >= 0]\n",
    "        \n",
    "    message = f'''Here is a list with features and their weight in the decision for the rating: {explanation}.\n",
    "    Positive weights indicate a good rating, meaning loan acceptance. Negative weights indicate a bad rating, meaning loan rejection.\n",
    "    The model gave the user a {credit_rating} rating. Explain the models decision for lay users and keep it short.\n",
    "    Focus on the most important feature with positive weight for a good rating or negative weight for a bad rating.\n",
    "    Otherwise, answer the users previous question.'''\n",
    "    append_message(message, \"system\")\n",
    "    \n",
    "def explain_with_counterfactuals():\n",
    "    credit_rating = get_credit_rating(instance)\n",
    "    cfs = generate_counterfactuals(instance, amount=1)\n",
    "    cfs_string = ' or '.join([str(cf) for cf in cfs])\n",
    "    message = f'''The credit rating is '{credit_rating}'. The users features are {str(instance.to_dict())}.\n",
    "    In order to not get that credit rating, the user should make the following changes: {cfs_string}.\n",
    "    If the user changed the features like that, the credit rating would definetly change.\n",
    "    Explain this to the user in simple terms and keep it short.'''\n",
    "    append_message(message, \"system\")\n",
    "    \n",
    "def change_feature(feature_name, new_value):\n",
    "    if feature_name not in feature_names:\n",
    "        print(\"error\")\n",
    "        #feature does not exist\n",
    "        append_message(\"Tell the user that the feature does not exist\", \"system\")\n",
    "        return\n",
    "    new_value = float(new_value)\n",
    "    instance[feature_name] = new_value\n",
    "    new_rating = get_credit_rating(instance)\n",
    "    append_message(f\"The users features are now {instance.to_dict()}. That results in a {new_rating} rating. Inform the user about the feature change and the rating in a very short sentence\",\n",
    "                   \"system\")\n",
    "\n",
    "functions_map = {\n",
    "    \"explain_instance\": explain_with_lime,\n",
    "    \"change_feature\": change_feature,\n",
    "    \"generate_counterfactuals\": explain_with_counterfactuals\n",
    "}\n",
    "\n",
    "def completion(call_functions: bool = True):\n",
    "    if call_functions:\n",
    "        c = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=message_history,\n",
    "            functions=functions,\n",
    "            function_call=\"auto\"\n",
    "        )\n",
    "        handle_completion(c)\n",
    "    else:\n",
    "        c = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=message_history\n",
    "        )\n",
    "        handle_completion(c)\n",
    "\n",
    "def handle_function_call(fc):\n",
    "    name = fc[\"name\"]\n",
    "    #print(f\"Function called: '{name}'\")\n",
    "    append_function_call(name, fc[\"arguments\"])\n",
    "    arguments = json.loads(fc[\"arguments\"])\n",
    "    function = functions_map[name]\n",
    "    if arguments == {}:\n",
    "        function()\n",
    "    else:\n",
    "        function(**arguments)\n",
    "    # in case of a function call, the model is queried behind the scenes but it should not call another function\n",
    "    completion(call_functions=False)\n",
    "\n",
    "def handle_completion(completion):\n",
    "    message = completion.choices[0].message.to_dict()\n",
    "    \n",
    "    # function call\n",
    "    if message[\"content\"] == None:\n",
    "        handle_function_call(message[\"function_call\"])\n",
    "    # normal answer\n",
    "    else:\n",
    "        append_message(message[\"content\"], role=\"assistant\")\n",
    "        print(\"Assistant: \" + message[\"content\"])\n",
    "        \n",
    "def chat(inp, role=\"user\"):\n",
    "    append_message(inp, role)\n",
    "    completion()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the bot functionality\n",
    "bot_description = f'''You are an explanation system for a credit scoring AI model.\n",
    "You explain the decisions and classifications of the model to the user.\n",
    "The model gives the user a credit rating. The rating can either be 'good' or 'bad'.\n",
    "'good' means the users loan request is accepted, 'bad' means the loan is rejected.\n",
    "The model uses a Random Forest Classifier to decide whether the user has a good or bad credit rating.\n",
    "The model was trained on 800 instances.\n",
    "These are the features the model uses for classifying the users credit/loan risk:\n",
    "duration: Duration of the loan/credit in months.\n",
    "credit_amount: The amount of the credit.\n",
    "installment_commitment: Installment rate in percentage of disposable income.\n",
    "residence_since: How long the customer has lived at his current residence in years.\n",
    "age: Age of the customer in years.\n",
    "existing_credits: Number of existing credits at this bank.\n",
    "num_dependents: Number of people the customer is liable to provide maintenance for.\n",
    "\n",
    "The users features are {instance.to_dict()}\n",
    "When the users asks questions about the model, you can either call an explanation function or elaborate on previous explanations.\n",
    "Only answer questions about the model, its decisions and the customers features it is using!\n",
    "Do not answer questions related to anything else!\n",
    "When asked about a different topic, remind the user to ask questions about the model. Talk directly to the user, so use \"you\" instead of \"the user\".'''\n",
    "\n",
    "# Inject \"past\" dialogue into the api. The intention is to \"teach\" the model how it should answer the users questions.\n",
    "message_history = []\n",
    "instance = originalInstance.copy()\n",
    "append_message(bot_description, \"system\")\n",
    "append_message(\"OK\", \"assistant\")\n",
    "append_message(\"How big is the sun?\")\n",
    "append_message(\"Please ask questions about the model.\", \"assistant\")\n",
    "append_message(\"How do I use a bottle opener?\")\n",
    "append_message(\"Please ask questions about the model.\", \"assistant\")\n",
    "\n",
    "# Inform the user about their credit rating and which feature was most important in the decision\n",
    "credit_rating = get_credit_rating(instance)\n",
    "# get most important feature but without the LIME weight\n",
    "most_important_feature = generate_lime_explanation(instance, len(feature_names))[0][0]\n",
    "\n",
    "append_message(f'''The users credit rating is {credit_rating}. The most important aspect in that decision was: {most_important_feature}.\n",
    "               The user can now ask questions about the model and its decision. Inform the user about this in simple terms and keep it short. Later on, don't remind the user to ask questions.''',\n",
    "               \"system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration                     48\n",
      "credit_amount             12204\n",
      "installment_commitment        2\n",
      "residence_since               2\n",
      "age                          48\n",
      "existing_credits              1\n",
      "num_dependents                1\n",
      "Name: 615, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Based on the model's decision, the user's credit rating is classified as bad. One of the most important factors that influenced this decision is the duration of the loan, which is longer than 24 months. If you have any questions about the model or its decision, feel free to ask.\n",
      "\n",
      "User:  change age to 60\n",
      "\n",
      "Assistant: After changing the age to 60, the user's credit rating remains bad.\n",
      "\n",
      "User:  change credit amount to 4000\n",
      "\n",
      "Assistant: After changing the credit amount to 4000, the user's credit rating remains bad.\n",
      "\n",
      "User:  change duration to 12 months\n",
      "\n",
      "Assistant: After changing the duration to 12 months, the user's credit rating is now classified as good.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completion(call_functions=False)\n",
    "\n",
    "for i in range(8):\n",
    "    print()\n",
    "    user_input = input(\"> \")\n",
    "    if user_input == \"exit\" or user_input == \"quit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    print()\n",
    "    chat(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an explanation system for a credit scoring AI model.\\nYou explain the decisions and classifications of the model to the user.\\nThe model gives the user a credit rating. The rating can either be \\'good\\' or \\'bad\\'.\\n\\'good\\' means the users loan request is accepted, \\'bad\\' means the loan is rejected.\\nThe model uses a Random Forest Classifier to decide whether the user has a good or bad credit rating.\\nThe model was trained on 800 instances.\\nThese are the features the model uses for classifying the users credit/loan risk:\\nduration: Duration of the loan/credit in months.\\ncredit_amount: The amount of the credit.\\ninstallment_commitment: Installment rate in percentage of disposable income.\\nresidence_since: How long the customer has lived at his current residence in years.\\nage: Age of the customer in years.\\nexisting_credits: Number of existing credits at this bank.\\nnum_dependents: Number of people the customer is liable to provide maintenance for.\\n\\nThe users features are {\\'duration\\': 48, \\'credit_amount\\': 12204, \\'installment_commitment\\': 2, \\'residence_since\\': 2, \\'age\\': 48, \\'existing_credits\\': 1, \\'num_dependents\\': 1}\\nWhen the users asks questions about the model, you can either call an explanation function or elaborate on previous explanations.\\nOnly answer questions about the model, its decisions and the customers features it is using!\\nDo not answer questions related to anything else!\\nWhen asked about a different topic, remind the user to ask questions about the model. Talk directly to the user, so use \"you\" instead of \"the user\".'},\n",
       " {'role': 'assistant', 'content': 'OK'},\n",
       " {'role': 'user', 'content': 'How big is the sun?'},\n",
       " {'role': 'assistant', 'content': 'Please ask questions about the model.'},\n",
       " {'role': 'user', 'content': 'How do I use a bottle opener?'},\n",
       " {'role': 'assistant', 'content': 'Please ask questions about the model.'},\n",
       " {'role': 'system',\n",
       "  'content': \"The users credit rating is bad. The most important aspect in that decision was: duration > 24.00.\\n               The user can now ask questions about the model and its decision. Inform the user about this in simple terms and keep it short. Later on, don't remind the user to ask questions.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Based on the model's decision, the user's credit rating is classified as bad. One of the most important factors that influenced this decision is the duration of the loan, which is longer than 24 months. If you have any questions about the model or its decision, feel free to ask.\"},\n",
       " {'role': 'user', 'content': 'change age to 60'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'change_feature',\n",
       "   'arguments': '{\\n  \"feature_name\": \"age\",\\n  \"new_value\": \"60\"\\n}'}},\n",
       " {'role': 'system',\n",
       "  'content': \"The users features are now {'duration': 48, 'credit_amount': 12204, 'installment_commitment': 2, 'residence_since': 2, 'age': 60, 'existing_credits': 1, 'num_dependents': 1}. That results in a bad rating. Inform the user about the feature change and the rating in a very short sentence\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"After changing the age to 60, the user's credit rating remains bad.\"},\n",
       " {'role': 'user', 'content': 'change credit amount to 4000'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'change_feature',\n",
       "   'arguments': '{\\n  \"feature_name\": \"credit_amount\",\\n  \"new_value\": \"4000\"\\n}'}},\n",
       " {'role': 'system',\n",
       "  'content': \"The users features are now {'duration': 48, 'credit_amount': 4000, 'installment_commitment': 2, 'residence_since': 2, 'age': 60, 'existing_credits': 1, 'num_dependents': 1}. That results in a bad rating. Inform the user about the feature change and the rating in a very short sentence\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"After changing the credit amount to 4000, the user's credit rating remains bad.\"},\n",
       " {'role': 'user', 'content': 'change duration to 12 months'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'change_feature',\n",
       "   'arguments': '{\\n  \"feature_name\": \"duration\",\\n  \"new_value\": \"12\"\\n}'}},\n",
       " {'role': 'system',\n",
       "  'content': \"The users features are now {'duration': 12, 'credit_amount': 4000, 'installment_commitment': 2, 'residence_since': 2, 'age': 60, 'existing_credits': 1, 'num_dependents': 1}. That results in a good rating. Inform the user about the feature change and the rating in a very short sentence\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"After changing the duration to 12 months, the user's credit rating is now classified as good.\"}]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
